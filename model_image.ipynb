{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dipp-12/vowel-detection/blob/main/model_image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kzPPkiE8hXC"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4upN9RjTeJn",
        "outputId": "0be7e15c-fa79-4d65-d810-21c4d911d38f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfcJmcJvZKk9"
      },
      "outputs": [],
      "source": [
        "classifier_face = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "classifier_smile = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAuxDrHWYBUO"
      },
      "outputs": [],
      "source": [
        "list_image = []\n",
        "status = []\n",
        "\n",
        "for name in glob.glob('/content/drive/MyDrive/colab_content/fungsi_1/0/*.jpg'):\n",
        "  image = cv2.imread(name)\n",
        "\n",
        "  gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  objects_face = classifier_face.detectMultiScale(gray_image)\n",
        "\n",
        "  for (x, y, w, h) in objects_face:\n",
        "    face_image = image[y:y+h, x:x+w]\n",
        "\n",
        "  gray_face = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)\n",
        "  objects_smile = classifier_smile.detectMultiScale(gray_face)\n",
        "\n",
        "  # Select the object of interest based on its lower middle position in the image\n",
        "  selected_object = None\n",
        "  for (x, y, w, h) in objects_smile:\n",
        "      cx = x + w // 2\n",
        "      cy = y + h\n",
        "      if selected_object is None or cy > selected_object[1]:\n",
        "          selected_object = (cx, cy, w, h)\n",
        "\n",
        "   # Draw a rectangle around the selected object\n",
        "  if selected_object is not None:\n",
        "      cx, cy, w, h = selected_object\n",
        "      object_image = face_image[cy-h:cy, cx-w//2:cx+w//2]\n",
        "\n",
        "  list_image.append(object_image)\n",
        "  status.append(0)\n",
        "\n",
        "for name in glob.glob('/content/drive/MyDrive/colab_content/fungsi_1/1/*.jpg'):\n",
        "  image = cv2.imread(name)\n",
        "\n",
        "  gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  objects_face = classifier_face.detectMultiScale(gray_image)\n",
        "\n",
        "  for (x, y, w, h) in objects_face:\n",
        "    face_image = image[y:y+h, x:x+w]\n",
        "\n",
        "  gray_face = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)\n",
        "  objects_smile = classifier_smile.detectMultiScale(gray_face)\n",
        "\n",
        "  # Select the object of interest based on its lower middle position in the image\n",
        "  selected_object = None\n",
        "  for (x, y, w, h) in objects_smile:\n",
        "      cx = x + w // 2\n",
        "      cy = y + h\n",
        "      if selected_object is None or cy > selected_object[1]:\n",
        "          selected_object = (cx, cy, w, h)\n",
        "\n",
        "   # Draw a rectangle around the selected object\n",
        "  if selected_object is not None:\n",
        "      cx, cy, w, h = selected_object\n",
        "      object_image = face_image[cy-h:cy, cx-w//2:cx+w//2]\n",
        "\n",
        "  list_image.append(object_image)\n",
        "  status.append(1)\n",
        "\n",
        "\n",
        "\n",
        "for name in glob.glob('/content/drive/MyDrive/colab_content/fungsi_1/2/*.jpg'):\n",
        "  image = cv2.imread(name)\n",
        "\n",
        "  gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  objects_face = classifier_face.detectMultiScale(gray_image)\n",
        "\n",
        "  for (x, y, w, h) in objects_face:\n",
        "    face_image = image[y:y+h, x:x+w]\n",
        "\n",
        "  gray_face = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)\n",
        "  objects_smile = classifier_smile.detectMultiScale(gray_face)\n",
        "\n",
        "  # Select the object of interest based on its lower middle position in the image\n",
        "  selected_object = None\n",
        "  for (x, y, w, h) in objects_smile:\n",
        "      cx = x + w // 2\n",
        "      cy = y + h\n",
        "      if selected_object is None or cy > selected_object[1]:\n",
        "          selected_object = (cx, cy, w, h)\n",
        "\n",
        "   # Draw a rectangle around the selected object\n",
        "  if selected_object is not None:\n",
        "      cx, cy, w, h = selected_object\n",
        "      object_image = face_image[cy-h:cy, cx-w//2:cx+w//2]\n",
        "\n",
        "  list_image.append(object_image)\n",
        "  status.append(2)\n",
        "\n",
        "for name in glob.glob('/content/drive/MyDrive/colab_content/fungsi_1/3/*.jpg'):\n",
        "  image = cv2.imread(name)\n",
        "\n",
        "  gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  objects_face = classifier_face.detectMultiScale(gray_image)\n",
        "\n",
        "  for (x, y, w, h) in objects_face:\n",
        "    face_image = image[y:y+h, x:x+w]\n",
        "\n",
        "  gray_face = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)\n",
        "  objects_smile = classifier_smile.detectMultiScale(gray_face)\n",
        "\n",
        "  # Select the object of interest based on its lower middle position in the image\n",
        "  selected_object = None\n",
        "  for (x, y, w, h) in objects_smile:\n",
        "      cx = x + w // 2\n",
        "      cy = y + h\n",
        "      if selected_object is None or cy > selected_object[1]:\n",
        "          selected_object = (cx, cy, w, h)\n",
        "\n",
        "   # Draw a rectangle around the selected object\n",
        "  if selected_object is not None:\n",
        "      cx, cy, w, h = selected_object\n",
        "      object_image = face_image[cy-h:cy, cx-w//2:cx+w//2]\n",
        "\n",
        "  list_image.append(object_image)\n",
        "  status.append(3)\n",
        "\n",
        "for name in glob.glob('/content/drive/MyDrive/colab_content/fungsi_1/4/*.jpg'):\n",
        "  image = cv2.imread(name)\n",
        "\n",
        "  gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  objects_face = classifier_face.detectMultiScale(gray_image)\n",
        "\n",
        "  for (x, y, w, h) in objects_face:\n",
        "    face_image = image[y:y+h, x:x+w]\n",
        "\n",
        "  gray_face = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)\n",
        "  objects_smile = classifier_smile.detectMultiScale(gray_face)\n",
        "\n",
        "  # Select the object of interest based on its lower middle position in the image\n",
        "  selected_object = None\n",
        "  for (x, y, w, h) in objects_smile:\n",
        "      cx = x + w // 2\n",
        "      cy = y + h\n",
        "      if selected_object is None or cy > selected_object[1]:\n",
        "          selected_object = (cx, cy, w, h)\n",
        "\n",
        "   # Draw a rectangle around the selected object\n",
        "  if selected_object is not None:\n",
        "      cx, cy, w, h = selected_object\n",
        "      object_image = face_image[cy-h:cy, cx-w//2:cx+w//2]\n",
        "\n",
        "  list_image.append(object_image)\n",
        "  status.append(4)\n",
        "\n",
        "for name in glob.glob('/content/drive/MyDrive/colab_content/fungsi_1/5/*.jpg'):\n",
        "  image = cv2.imread(name)\n",
        "\n",
        "  gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  objects_face = classifier_face.detectMultiScale(gray_image)\n",
        "\n",
        "  for (x, y, w, h) in objects_face:\n",
        "    face_image = image[y:y+h, x:x+w]\n",
        "\n",
        "  gray_face = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)\n",
        "  objects_smile = classifier_smile.detectMultiScale(gray_face)\n",
        "\n",
        "  # Select the object of interest based on its lower middle position in the image\n",
        "  selected_object = None\n",
        "  for (x, y, w, h) in objects_smile:\n",
        "      cx = x + w // 2\n",
        "      cy = y + h\n",
        "      if selected_object is None or cy > selected_object[1]:\n",
        "          selected_object = (cx, cy, w, h)\n",
        "\n",
        "   # Draw a rectangle around the selected object\n",
        "  if selected_object is not None:\n",
        "      cx, cy, w, h = selected_object\n",
        "      object_image = face_image[cy-h:cy, cx-w//2:cx+w//2]\n",
        "\n",
        "  list_image.append(object_image)\n",
        "  status.append(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55XyKoKYGI24"
      },
      "outputs": [],
      "source": [
        "img_size = [max(i.shape) for i in list_image]\n",
        "max_res = max(img_size)\n",
        "\n",
        "for i, k in enumerate(list_image):\n",
        "  list_image[i] = cv2.resize(list_image[i], (max_res,max_res))/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvHSMgZJpZ3U"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "z = list(zip(list_image,status))\n",
        "random.shuffle(z)\n",
        "x, y = zip(*z)\n",
        "x = np.asarray(x)\n",
        "y = np.asarray(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCs0N-PliZME",
        "outputId": "bf219fe2-f594-4fa2-942b-7d178248a169"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 382, 382, 8)       224       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 191, 191, 8)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 189, 189, 16)      1168      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 94, 94, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 92, 92, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 46, 46, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 67712)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               6771300   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 606       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,777,938\n",
            "Trainable params: 6,777,938\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(8, (3,3), input_shape=x.shape[1:], activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(16,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(32,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100,activation='relu'))\n",
        "model.add(Dense(6,activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwWPqvdVjdPe",
        "outputId": "86d839df-e494-4b4c-8c18-942d6b2d4a63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "881/881 [==============================] - 121s 136ms/step - loss: 1.7558 - accuracy: 0.2883 - val_loss: 1.6453 - val_accuracy: 0.3258\n",
            "Epoch 2/50\n",
            "881/881 [==============================] - 121s 138ms/step - loss: 1.4147 - accuracy: 0.5006 - val_loss: 1.3219 - val_accuracy: 0.5068\n",
            "Epoch 3/50\n",
            "881/881 [==============================] - 120s 137ms/step - loss: 1.0440 - accuracy: 0.6447 - val_loss: 0.6789 - val_accuracy: 0.7466\n",
            "Epoch 4/50\n",
            "881/881 [==============================] - 121s 137ms/step - loss: 0.7356 - accuracy: 0.7367 - val_loss: 0.5628 - val_accuracy: 0.8054\n",
            "Epoch 5/50\n",
            "881/881 [==============================] - 119s 135ms/step - loss: 0.5542 - accuracy: 0.7957 - val_loss: 0.6819 - val_accuracy: 0.7692\n",
            "Epoch 6/50\n",
            "881/881 [==============================] - 121s 137ms/step - loss: 0.5311 - accuracy: 0.8297 - val_loss: 0.5536 - val_accuracy: 0.8462\n",
            "Epoch 7/50\n",
            "881/881 [==============================] - 121s 137ms/step - loss: 0.4390 - accuracy: 0.8672 - val_loss: 0.7241 - val_accuracy: 0.7828\n",
            "Epoch 8/50\n",
            "881/881 [==============================] - 118s 134ms/step - loss: 0.3404 - accuracy: 0.8956 - val_loss: 0.3971 - val_accuracy: 0.8869\n",
            "Epoch 9/50\n",
            "881/881 [==============================] - 121s 137ms/step - loss: 0.3521 - accuracy: 0.9001 - val_loss: 0.3120 - val_accuracy: 0.9321\n",
            "Epoch 10/50\n",
            "881/881 [==============================] - 120s 137ms/step - loss: 0.2874 - accuracy: 0.9058 - val_loss: 0.4558 - val_accuracy: 0.8778\n",
            "Epoch 11/50\n",
            "881/881 [==============================] - 118s 134ms/step - loss: 0.2290 - accuracy: 0.9251 - val_loss: 0.3632 - val_accuracy: 0.9367\n",
            "Epoch 12/50\n",
            "881/881 [==============================] - 120s 137ms/step - loss: 0.3317 - accuracy: 0.9047 - val_loss: 0.5632 - val_accuracy: 0.8100\n",
            "Epoch 13/50\n",
            "881/881 [==============================] - 120s 136ms/step - loss: 0.3424 - accuracy: 0.8785 - val_loss: 0.4489 - val_accuracy: 0.9005\n",
            "Epoch 14/50\n",
            "881/881 [==============================] - 120s 136ms/step - loss: 0.2426 - accuracy: 0.9387 - val_loss: 0.5121 - val_accuracy: 0.8597\n",
            "Epoch 15/50\n",
            "881/881 [==============================] - 118s 134ms/step - loss: 0.3125 - accuracy: 0.9069 - val_loss: 0.4739 - val_accuracy: 0.8416\n",
            "Epoch 16/50\n",
            "881/881 [==============================] - 120s 136ms/step - loss: 0.3522 - accuracy: 0.8842 - val_loss: 0.4659 - val_accuracy: 0.8914\n",
            "Epoch 17/50\n",
            "881/881 [==============================] - 120s 137ms/step - loss: 0.0945 - accuracy: 0.9739 - val_loss: 0.7105 - val_accuracy: 0.9005\n",
            "Epoch 18/50\n",
            "881/881 [==============================] - 118s 134ms/step - loss: 0.0984 - accuracy: 0.9728 - val_loss: 0.4359 - val_accuracy: 0.9321\n",
            "Epoch 19/50\n",
            "881/881 [==============================] - 120s 136ms/step - loss: 0.0632 - accuracy: 0.9864 - val_loss: 0.3534 - val_accuracy: 0.9457\n",
            "Epoch 20/50\n",
            "881/881 [==============================] - 120s 136ms/step - loss: 0.2325 - accuracy: 0.9637 - val_loss: 0.3982 - val_accuracy: 0.9005\n",
            "Epoch 21/50\n",
            "881/881 [==============================] - 118s 134ms/step - loss: 0.0937 - accuracy: 0.9818 - val_loss: 0.3270 - val_accuracy: 0.9457\n",
            "Epoch 22/50\n",
            "881/881 [==============================] - 120s 137ms/step - loss: 0.0200 - accuracy: 0.9955 - val_loss: 0.5372 - val_accuracy: 0.9457\n",
            "Epoch 23/50\n",
            "881/881 [==============================] - 120s 136ms/step - loss: 0.1763 - accuracy: 0.9694 - val_loss: 0.9640 - val_accuracy: 0.8688\n",
            "Epoch 24/50\n",
            "881/881 [==============================] - 118s 134ms/step - loss: 0.2085 - accuracy: 0.9682 - val_loss: 0.5324 - val_accuracy: 0.9367\n",
            "Epoch 25/50\n",
            "881/881 [==============================] - 120s 137ms/step - loss: 0.0137 - accuracy: 0.9977 - val_loss: 0.6879 - val_accuracy: 0.9457\n",
            "Epoch 26/50\n",
            "881/881 [==============================] - 120s 136ms/step - loss: 0.0046 - accuracy: 0.9977 - val_loss: 0.5507 - val_accuracy: 0.9367\n",
            "Epoch 27/50\n",
            "881/881 [==============================] - 121s 137ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6869 - val_accuracy: 0.9457\n",
            "Epoch 28/50\n",
            "881/881 [==============================] - 118s 134ms/step - loss: 6.2393e-05 - accuracy: 1.0000 - val_loss: 0.7044 - val_accuracy: 0.9457\n",
            "Epoch 29/50\n",
            "881/881 [==============================] - 120s 136ms/step - loss: 4.2974e-05 - accuracy: 1.0000 - val_loss: 0.7146 - val_accuracy: 0.9457\n",
            "Epoch 30/50\n",
            "881/881 [==============================] - 120s 136ms/step - loss: 3.1243e-05 - accuracy: 1.0000 - val_loss: 0.7333 - val_accuracy: 0.9457\n",
            "Epoch 31/50\n",
            "881/881 [==============================] - 118s 134ms/step - loss: 2.3253e-05 - accuracy: 1.0000 - val_loss: 0.7392 - val_accuracy: 0.9457\n",
            "Epoch 32/50\n",
            "881/881 [==============================] - 120s 137ms/step - loss: 1.6520e-05 - accuracy: 1.0000 - val_loss: 0.7599 - val_accuracy: 0.9457\n",
            "Epoch 33/50\n",
            "881/881 [==============================] - 120s 136ms/step - loss: 1.1457e-05 - accuracy: 1.0000 - val_loss: 0.7764 - val_accuracy: 0.9457\n",
            "Epoch 34/50\n",
            "881/881 [==============================] - 118s 134ms/step - loss: 7.8630e-06 - accuracy: 1.0000 - val_loss: 0.7904 - val_accuracy: 0.9457\n",
            "Epoch 35/50\n",
            "881/881 [==============================] - 120s 136ms/step - loss: 4.8861e-06 - accuracy: 1.0000 - val_loss: 0.8120 - val_accuracy: 0.9457\n",
            "Epoch 36/50\n",
            "881/881 [==============================] - 120s 136ms/step - loss: 3.3405e-06 - accuracy: 1.0000 - val_loss: 0.8310 - val_accuracy: 0.9457\n",
            "Epoch 37/50\n",
            "881/881 [==============================] - 118s 134ms/step - loss: 2.1044e-06 - accuracy: 1.0000 - val_loss: 0.8570 - val_accuracy: 0.9457\n",
            "Epoch 38/50\n",
            "881/881 [==============================] - 120s 136ms/step - loss: 1.2612e-06 - accuracy: 1.0000 - val_loss: 0.8903 - val_accuracy: 0.9457\n",
            "Epoch 39/50\n",
            "881/881 [==============================] - 121s 137ms/step - loss: 8.4906e-07 - accuracy: 1.0000 - val_loss: 0.8970 - val_accuracy: 0.9457\n",
            "Epoch 40/50\n",
            "881/881 [==============================] - 119s 135ms/step - loss: 6.4232e-07 - accuracy: 1.0000 - val_loss: 0.9142 - val_accuracy: 0.9457\n",
            "Epoch 41/50\n",
            "881/881 [==============================] - 124s 141ms/step - loss: 3.8739e-07 - accuracy: 1.0000 - val_loss: 0.9385 - val_accuracy: 0.9457\n",
            "Epoch 42/50\n",
            "881/881 [==============================] - 121s 138ms/step - loss: 2.5858e-07 - accuracy: 1.0000 - val_loss: 0.9578 - val_accuracy: 0.9457\n",
            "Epoch 43/50\n",
            "881/881 [==============================] - 118s 134ms/step - loss: 1.5615e-07 - accuracy: 1.0000 - val_loss: 0.9745 - val_accuracy: 0.9457\n",
            "Epoch 44/50\n",
            "881/881 [==============================] - 120s 136ms/step - loss: 1.2381e-07 - accuracy: 1.0000 - val_loss: 0.9885 - val_accuracy: 0.9457\n",
            "Epoch 45/50\n",
            "881/881 [==============================] - 120s 136ms/step - loss: 6.9415e-08 - accuracy: 1.0000 - val_loss: 1.0106 - val_accuracy: 0.9457\n",
            "Epoch 46/50\n",
            "881/881 [==============================] - 118s 134ms/step - loss: 4.5735e-08 - accuracy: 1.0000 - val_loss: 1.0179 - val_accuracy: 0.9457\n",
            "Epoch 47/50\n",
            "881/881 [==============================] - 120s 137ms/step - loss: 3.2339e-08 - accuracy: 1.0000 - val_loss: 1.0753 - val_accuracy: 0.9457\n",
            "Epoch 48/50\n",
            "881/881 [==============================] - 120s 136ms/step - loss: 2.1379e-08 - accuracy: 1.0000 - val_loss: 1.0547 - val_accuracy: 0.9457\n",
            "Epoch 49/50\n",
            "881/881 [==============================] - 118s 134ms/step - loss: 1.4614e-08 - accuracy: 1.0000 - val_loss: 1.1123 - val_accuracy: 0.9457\n",
            "Epoch 50/50\n",
            "881/881 [==============================] - 120s 136ms/step - loss: 9.0659e-09 - accuracy: 1.0000 - val_loss: 1.1520 - val_accuracy: 0.9412\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb1d6f91880>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "model.fit(\n",
        "    x,\n",
        "    y,\n",
        "    batch_size=1,\n",
        "    epochs=50,\n",
        "    validation_split=0.2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Czvw20PfaWcq"
      },
      "outputs": [],
      "source": [
        "model.save_weights('model_image.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oio48o5HOdWc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5c329ec-e291-48ad-f0b8-28cca77b9b93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "max_res"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNxn64fgsruHpgJTbMZDqd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}